{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Website Scraping Exercise 01**\n",
    "\n",
    "\n",
    "**Website**: ESDM MODI\n",
    "\n",
    "**Disclaimer**: The dataset included here is obtained from the ESDM MODI website and is strictly used for educational and non-commercial purposes. I do not claim ownership of the data and am using it solely for practice and learning exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Libraries:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a function to retrieve details from the specific page of a company:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring function to get the details of data\n",
    "\n",
    "def get_company_code(soup):\n",
    "    try:\n",
    "        row = soup.find('th', string = \"Kode Perusahaan\").find_parent('tr')   \n",
    "        return row.find_all('td')[-1].get_text(strip=True)\n",
    "    except AttributeError:\n",
    "        return None\n",
    "    \n",
    "def get_company_name(soup):\n",
    "    try:\n",
    "        row = soup.find('th', string= \"Nama Perusahaan\").find_parent('tr')\n",
    "        return row.find_all('td')[1].get_text(strip=True)\n",
    "    except AttributeError:\n",
    "        return None\n",
    "    \n",
    "# Declaring function for business_entity\n",
    "def get_business_entity(soup):\n",
    "    try:\n",
    "        row = soup.find('th', string=\"Jenis Badan Usaha\").find_parent('tr')\n",
    "        return row.find_all('td')[-1].get_text(strip=True)\n",
    "    except AttributeError:\n",
    "        return None\n",
    "    \n",
    "# Declaring function for no_deed\n",
    "def get_no_deed(soup):\n",
    "    try:\n",
    "        row = soup.find('th', string = \"No. Akte\").find_parent('tr')\n",
    "        return row.find_all('td')[-1].get_text(strip=True)\n",
    "    except AttributeError:\n",
    "        return None\n",
    "    \n",
    "\n",
    "# Declaring function for date_deed\n",
    "def get_date_deed(soup):\n",
    "    try:\n",
    "        row = soup.find('th', string = \"Tgl. Akte\").find_parent('tr')\n",
    "        return row.find_all('td')[-1].get_text(strip=True)\n",
    "    except AttributeError:\n",
    "        return None\n",
    "    \n",
    "\n",
    "# Declaring function to get office flag\n",
    "def get_office_flag(soup):\n",
    "    try:\n",
    "        row = soup.find('div', class_ =\"col-md-9 table-responsive\")\n",
    "        office_flag_tag = row.find_all('td', class_ = \"\")\n",
    "        office_flag = office_flag_tag[1].get_text(strip=True)\n",
    "    except AttributeError:\n",
    "        return None\n",
    "    \n",
    "    return office_flag\n",
    "\n",
    "\n",
    "# Declaring function to get office address\n",
    "def get_office_address(soup):\n",
    "    try:\n",
    "        row = soup.find('div', class_ =\"col-md-9 table-responsive\")\n",
    "        tag = row.find_all('td', class_ = \"\")\n",
    "        office_address = tag[2].get_text(strip=True)\n",
    "    except AttributeError:\n",
    "        return None\n",
    "    \n",
    "    return office_address\n",
    "\n",
    "# Declaring function to get contact_person\n",
    "def get_contact_person(soup):\n",
    "    try:\n",
    "        row = soup.find('div', class_ =\"col-md-9 table-responsive\")\n",
    "        tag = row.find_all('td', class_ = \"\")\n",
    "        contact_person = tag[3].get_text(strip=True)\n",
    "    except AttributeError:\n",
    "        return None\n",
    "    \n",
    "    return contact_person\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Main Program:**\n",
    "\n",
    "Main program activities include:\n",
    "\n",
    "1. Generating company links/URLs by iterating through 20 pages, necessary due to the paginated list.\n",
    "2. Extracting all details from the company links/URLs generated in the previous step.\n",
    "3. Compiling all retrieved details into a dataframe through iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1 of 20\n",
      "Scraping page 2 of 20\n",
      "Scraping page 3 of 20\n",
      "Scraping page 4 of 20\n",
      "Scraping page 5 of 20\n",
      "Scraping page 6 of 20\n",
      "Scraping page 7 of 20\n",
      "Scraping page 8 of 20\n",
      "Scraping page 9 of 20\n",
      "Scraping page 10 of 20\n",
      "Scraping page 11 of 20\n",
      "Scraping page 12 of 20\n",
      "Scraping page 13 of 20\n",
      "Scraping page 14 of 20\n",
      "Scraping page 15 of 20\n",
      "Scraping page 16 of 20\n",
      "Scraping page 17 of 20\n",
      "Scraping page 18 of 20\n",
      "Scraping page 19 of 20\n",
      "Scraping page 20 of 20\n"
     ]
    }
   ],
   "source": [
    "# Declaring necessary variables\n",
    "base_url = \"https://modi.esdm.go.id/portal/dataPerusahaan\"\n",
    "total_pages = 20\n",
    "all_company_links = []\n",
    "\n",
    "# Iteration to generate pagenated links, number of total pages refer to total_pages\n",
    "for page in range(1, total_pages +1):\n",
    "    print(f\"Scraping page {page} of {total_pages}\")\n",
    "\n",
    "    page_url = f\"{base_url}?=page{page}\"\n",
    "\n",
    "    response_page = requests.get(page_url)\n",
    "\n",
    "    soup = BeautifulSoup(response_page.text, 'lxml')\n",
    "\n",
    "    # Iteration to generate company_link/url, and store it to all_company_links stack\n",
    "    for a_tag in soup.find_all('a', href=True):\n",
    "        if \"portal/detailPerusahaan/\" in a_tag['href']:\n",
    "            company_link = a_tag['href']\n",
    "            all_company_links.append(company_link)\n",
    "\n",
    "# Create interval for 2s between iteration: Be Polite to the server that arent yours!\n",
    "time.sleep(2)\n",
    "\n",
    "# Creating Dictionary to prepare for dataframe creation\n",
    "result = {'company_code': [], 'company_name': [], 'business_entity': [], 'no_deed': [], 'date_deed': [], 'office_flag': [], 'office_address': [], 'contact_person': []}\n",
    "\n",
    "# Iterate the the company link gathered from previous iteration, to generate \n",
    "for link in all_company_links:\n",
    "    new_page = requests.get(link)\n",
    "    new_soup = BeautifulSoup(new_page.text, 'lxml')\n",
    "\n",
    "    result['company_code'].append(get_company_code(new_soup))\n",
    "    result['company_name'].append(get_company_name(new_soup))\n",
    "    result['business_entity'].append(get_business_entity(new_soup))\n",
    "    result['no_deed'].append(get_no_deed(new_soup))\n",
    "    result['date_deed'].append(get_date_deed(new_soup))\n",
    "    result['office_flag'].append(get_office_flag(new_soup))\n",
    "    result['office_address'].append(get_office_address(new_soup))\n",
    "    result['contact_person'].append(get_contact_person(new_soup))\n",
    "\n",
    "# Create interval for 2s between iteration: Be Polite to the server that arent yours!\n",
    "time.sleep(2)\n",
    "\n",
    "# Create dataframe from dictionary\n",
    "dataset_modi = pd.DataFrame.from_dict(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Transformation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   company_code     400 non-null    int64         \n",
      " 1   company_name     400 non-null    string        \n",
      " 2   business_entity  400 non-null    string        \n",
      " 3   no_deed          400 non-null    string        \n",
      " 4   date_deed        140 non-null    datetime64[ns]\n",
      " 5   office_flag      400 non-null    string        \n",
      " 6   office_address   400 non-null    string        \n",
      " 7   contact_person   400 non-null    string        \n",
      "dtypes: datetime64[ns](1), int64(1), string(6)\n",
      "memory usage: 25.1 KB\n"
     ]
    }
   ],
   "source": [
    "#datatype transform\n",
    "dataset_modi['company_code']    = dataset_modi['company_code'].astype('int64')\n",
    "dataset_modi['company_name']    = dataset_modi['company_name'].astype('string')\n",
    "dataset_modi['business_entity'] = dataset_modi['business_entity'].astype('string')\n",
    "dataset_modi['no_deed']         = dataset_modi['no_deed'].astype('string')\n",
    "dataset_modi['date_deed']       = pd.to_datetime(dataset_modi['date_deed'])\n",
    "dataset_modi['office_flag']     = dataset_modi['office_flag'].astype('string')\n",
    "dataset_modi['office_address']  = dataset_modi['office_address'].astype('string')\n",
    "dataset_modi['contact_person']  = dataset_modi['contact_person'].astype('string')\n",
    "\n",
    "dataset_modi.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Export data to .CSV:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting dataframe to .csv file\n",
    "\n",
    "export_path = r\"C:\\Users\\user\\OneDrive\\RFA _Personal Files\\02. COURSE\\Purwadhika_Data Engineering\\Purwadhika_VS\\meet42_scraping\\data_modi\\data_modi.csv\"\n",
    "\n",
    "dataset_modi.to_csv(export_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
